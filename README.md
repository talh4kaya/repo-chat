# ğŸ§  Repo-Chat: Privacy-First Local RAG Assistant

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-0.3-green?style=for-the-badge&logo=chainlink&logoColor=white)
![Ollama](https://img.shields.io/badge/Model-Llama3-orange?style=for-the-badge&logo=meta&logoColor=white)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red?style=for-the-badge&logo=streamlit&logoColor=white)
![ChromaDB](https://img.shields.io/badge/VectorDB-Chroma-purple?style=for-the-badge)

<br>

**Kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸan, internet gerektirmeyen ve kodlarÄ±nÄ±zÄ± analiz eden kiÅŸisel Yapay Zeka AsistanÄ±nÄ±z.**

[Kurulum](#-kurulum) â€¢ [KullanÄ±m](#-kullanÄ±m) â€¢ [Mimari](#-mimari-ve-Ã§alÄ±ÅŸma-mantÄ±ÄŸÄ±) â€¢ [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)

</div>

---

## ğŸ“– Proje HakkÄ±nda

**Repo-Chat**, GitHub Ã¼zerindeki herhangi bir kod tabanÄ±nÄ± (repository) indirip analiz eden ve **Yerel Yapay Zeka (Local LLM)** kullanarak bu kodlarla sohbet etmenizi saÄŸlayan bir **RAG (Retrieval-Augmented Generation)** uygulamasÄ±dÄ±r.

Bu proje, **veri gizliliÄŸini** en Ã¼st dÃ¼zeyde tutar. KodlarÄ±nÄ±z 3. parti sunuculara (OpenAI, Claude vb.) gÃ¶nderilmez; her ÅŸey kendi bilgisayarÄ±nÄ±zda, **RTX GPU gÃ¼cÃ¼yle** iÅŸlenir.

### âœ¨ Temel Ã–zellikler

* ğŸ”’ **%100 Gizlilik:** Verileriniz ve kodlarÄ±nÄ±z lokal makinenizi asla terk etmez.
* ğŸ§  **Llama 3 GÃ¼cÃ¼:** Meta'nÄ±n en geliÅŸmiÅŸ aÃ§Ä±k kaynak modeli ile zeki ve baÄŸlamÄ± anlayan cevaplar.
* âš¡ **VektÃ¶r Arama:** **ChromaDB** ve **HuggingFace Embeddings** ile kodlar arasÄ±nda anlamsal arama.
* ğŸ¨ **Modern UI:** **Streamlit** ile geliÅŸtirilmiÅŸ, Ã¶zelleÅŸtirilebilir ve kullanÄ±cÄ± dostu arayÃ¼z.

---

## ğŸ“‚ Proje YapÄ±sÄ±

```bash
repo-chat/
â”œâ”€â”€ ğŸ“‚ chroma_db/          # VektÃ¶r veritabanÄ± (Git-ignored)
â”œâ”€â”€ ğŸ“‚ downloaded_repo/    # Analiz edilen repo (Git-ignored)
â”œâ”€â”€ ğŸ“‚ .streamlit/         # ArayÃ¼z tema ayarlarÄ±
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ app.py                 # Ana Streamlit uygulamasÄ± (Chat ArayÃ¼zÃ¼)
â”œâ”€â”€ ingest.py              # Veri iÅŸleme ve veritabanÄ± oluÅŸturma scripti
â”œâ”€â”€ requirements.txt       # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md              # DokÃ¼mantasyon





ğŸ›  Kurulum
Projeyi kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin.

1. Gereksinimler
Python 3.9 veya Ã¼zeri

Git

Ollama (Modeli Ã§alÄ±ÅŸtÄ±rmak iÃ§in gereklidir. Ä°ndir)

2. Kurulum AdÄ±mlarÄ±
Bash

# 1. Repoyu klonlayÄ±n
git clone [https://github.com/talh4kaya/repo-chat.git](https://github.com/talh4kaya/repo-chat.git)
cd repo-chat

# 2. Sanal ortam oluÅŸturun
python -m venv venv

# 3. Sanal ortamÄ± aktif edin
# Windows iÃ§in:
.\venv\Scripts\activate
# Mac/Linux iÃ§in:
# source venv/bin/activate

# 4. KÃ¼tÃ¼phaneleri yÃ¼kleyin
pip install -r requirements.txt
3. Modelin HazÄ±rlanmasÄ±
Terminalde aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rarak Llama 3 modelini indirin:

Bash

ollama run llama3
ğŸš€ KullanÄ±m
AdÄ±m 1: KodlarÄ± HafÄ±zaya At (Ingestion)
Analiz etmek istediÄŸiniz GitHub reposunu ingest.py dosyasÄ± iÃ§indeki REPO_URL deÄŸiÅŸkenine yazÄ±n ve Ã§alÄ±ÅŸtÄ±rÄ±n:

Bash

python ingest.py
(Bu iÅŸlem kodlarÄ± indirir, parÃ§alar, vektÃ¶rlere Ã§evirir ve ChromaDB veritabanÄ±na kaydeder).

AdÄ±m 2: AsistanÄ± BaÅŸlat
VeritabanÄ± oluÅŸtuktan sonra arayÃ¼zÃ¼ baÅŸlatÄ±n:

Bash

streamlit run app.py
TarayÄ±cÄ±nÄ±zda aÃ§Ä±lan ekrandan kodlarÄ±nÄ±zla konuÅŸmaya baÅŸlayabilirsiniz! ğŸ‰

ğŸ— Mimari ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±
Bu proje RAG (Retrieval-Augmented Generation) mimarisini kullanÄ±r. Veri akÄ±ÅŸÄ± aÅŸaÄŸÄ±daki gibidir:

Ingestion (Yutma): gitpython ile repo indirilir.

Splitting (ParÃ§alama): Kod dosyalarÄ± RecursiveCharacterTextSplitter ile anlamlÄ± parÃ§alara bÃ¶lÃ¼nÃ¼r.

Embedding (GÃ¶mme): Her parÃ§a HuggingFaceEmbeddings ile sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

Vector Store (HafÄ±za): VektÃ¶rler ChromaDB iÃ§inde saklanÄ±r.

Retrieval & Chat: KullanÄ±cÄ± sorusu ile en alakalÄ± kod parÃ§alarÄ± bulunur ve Llama 3 modeline gÃ¶nderilir.

ğŸ“Š AkÄ±ÅŸ ÅemasÄ±

graph TD;
    A[GitHub Repo] -->|Clone| B(Kod DosyalarÄ±);
    B -->|Split| C(Kod ParÃ§acÄ±klarÄ±);
    C -->|Embedding| D[(ChromaDB VektÃ¶r VeritabanÄ±)];
    E[KullanÄ±cÄ± Sorusu] -->|Search| D;
    D -->|AlakalÄ± Kodlar| F[Llama 3 LLM];
    F -->|Cevap| G[Streamlit ArayÃ¼z];
    style D fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#bbf,stroke:#333,stroke-width:2px


ğŸ¤ KatkÄ±da Bulunma
Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r. Ã–nerilerinizi ve hata bildirimlerinizi Issue aÃ§arak veya Pull Request gÃ¶ndererek iletebilirsiniz.

ğŸ“œ Lisans
Bu proje MIT License altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

<p align="center"> Developed with â¤ï¸ by <strong>Talha Kaya</strong> </p>